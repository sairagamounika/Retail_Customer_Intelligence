{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "107ee875",
      "metadata": {},
      "source": [
        "# Churn Modeling for Customer Retention\n",
        "\n",
        "**Part 4 of 4 â€” Retail Customer Intelligence**  \n",
        "Predict who is likely to churn. Uses **train-only features** from Notebook 1 and churn labels from the holdout window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 200)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Train Features and Churn Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c53f57f",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = Path(\"..\") / \"data\" / \"processed\"\n",
        "MODELS_DIR = Path(\"..\") / \"models\"\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "features = pd.read_csv(DATA_DIR / \"customer_features_train.csv\", parse_dates=[\"last_purchase\"])\n",
        "labels = pd.read_csv(DATA_DIR / \"customer_churn_labels.csv\", parse_dates=[\"snapshot_date\", \"train_end\"])\n",
        "\n",
        "churn_df = features.merge(labels[[\"customer_id\", \"churned\"]], on=\"customer_id\", how=\"left\")\n",
        "churn_df[\"churned\"] = churn_df[\"churned\"].fillna(0).astype(int)\n",
        "\n",
        "churn_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "churn_rate = churn_df[\"churned\"].mean()\n",
        "print(f\"Churn rate: {churn_rate:.2%}\")\n",
        "\n",
        "plt.figure(figsize=(4, 3))\n",
        "churn_df[\"churned\"].value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Churn Distribution\")\n",
        "plt.xlabel(\"Churned (1=yes)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train/Validation Split (Time-Safe)\n",
        "\n",
        "We split by last purchase date to avoid leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort by last purchase and split chronologically\n",
        "churn_df = churn_df.sort_values(\"last_purchase\")\n",
        "split_idx = int(len(churn_df) * 0.8)\n",
        "\n",
        "train_df = churn_df.iloc[:split_idx].copy()\n",
        "val_df = churn_df.iloc[split_idx:].copy()\n",
        "\n",
        "X_train = train_df.drop(columns=[\"customer_id\", \"churned\", \"last_purchase\"])\n",
        "y_train = train_df[\"churned\"]\n",
        "\n",
        "X_val = val_df.drop(columns=[\"customer_id\", \"churned\", \"last_purchase\"])\n",
        "y_val = val_df[\"churned\"]\n",
        "\n",
        "X_train.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline Model: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
        "\n",
        "num_cols = X_train.select_dtypes(include=[\"number\"]).columns\n",
        "\n",
        "log_reg = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
        "])\n",
        "\n",
        "log_reg.fit(X_train[num_cols], y_train)\n",
        "\n",
        "val_probs_lr = log_reg.predict_proba(X_val[num_cols])[:, 1]\n",
        "val_pred_lr = (val_probs_lr >= 0.5).astype(int)\n",
        "\n",
        "print(\"LogReg ROC-AUC:\", roc_auc_score(y_val, val_probs_lr))\n",
        "print(classification_report(y_val, val_pred_lr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tree Model: Random Forest (Nonlinear Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    class_weight=\"balanced_subsample\",\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "rf.fit(X_train[num_cols], y_train)\n",
        "val_probs_rf = rf.predict_proba(X_val[num_cols])[:, 1]\n",
        "val_pred_rf = (val_probs_rf >= 0.5).astype(int)\n",
        "\n",
        "print(\"RF ROC-AUC:\", roc_auc_score(y_val, val_probs_rf))\n",
        "print(classification_report(y_val, val_pred_rf))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = [\n",
        "    (\"LogisticRegression\", roc_auc_score(y_val, val_probs_lr)),\n",
        "    (\"RandomForest\", roc_auc_score(y_val, val_probs_rf)),\n",
        "]\n",
        "\n",
        "if 'val_probs_xgb' in globals():\n",
        "    rows.append((\"XGBoost\", roc_auc_score(y_val, val_probs_xgb)))\n",
        "\n",
        "if 'val_probs_lgbm' in globals():\n",
        "    rows.append((\"LightGBM\", roc_auc_score(y_val, val_probs_lgbm)))\n",
        "\n",
        "results = pd.DataFrame(rows, columns=[\"model\", \"roc_auc\"]).sort_values(\"roc_auc\", ascending=False)\n",
        "results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calibration and Threshold Tuning\n",
        "\n",
        "We calibrate probabilities and select thresholds based on business cost/benefit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import brier_score_loss\n",
        "\n",
        "# Calibrate the RF model\n",
        "cal_rf = CalibratedClassifierCV(rf, method=\"isotonic\", cv=3)\n",
        "cal_rf.fit(X_train[num_cols], y_train)\n",
        "\n",
        "val_probs_rf_cal = cal_rf.predict_proba(X_val[num_cols])[:, 1]\n",
        "\n",
        "print(\"RF Brier (uncal):\", brier_score_loss(y_val, val_probs_rf))\n",
        "print(\"RF Brier (cal):\", brier_score_loss(y_val, val_probs_rf_cal))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Threshold selection using simple profit model\n",
        "# Example: outreach cost = 1, expected saved revenue = 10 if we correctly catch a churner\n",
        "COST = 1.0\n",
        "BENEFIT = 10.0\n",
        "\n",
        "thresholds = np.linspace(0.05, 0.95, 19)\n",
        "profits = []\n",
        "\n",
        "for t in thresholds:\n",
        "    preds = (val_probs_rf_cal >= t).astype(int)\n",
        "    tp = ((preds == 1) & (y_val == 1)).sum()\n",
        "    fp = ((preds == 1) & (y_val == 0)).sum()\n",
        "    profit = tp * BENEFIT - fp * COST\n",
        "    profits.append(profit)\n",
        "\n",
        "best_idx = int(np.argmax(profits))\n",
        "best_t = thresholds[best_idx]\n",
        "\n",
        "pd.DataFrame({\"threshold\": thresholds, \"profit\": profits}).sort_values(\"profit\", ascending=False).head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Precision-Recall Curve and F-score Threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_val, val_probs_rf_cal)\n",
        "\n",
        "# Avoid division by zero\n",
        "f1 = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "\n",
        "best_idx = int(np.argmax(f1))\n",
        "best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
        "\n",
        "print(\"Best F1:\", f1[best_idx])\n",
        "print(\"Best threshold:\", best_threshold)\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve (Calibrated RF)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradient Boosting Models (XGBoost / LightGBM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# XGBoost (if installed)\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "\n",
        "    xgb = XGBClassifier(\n",
        "        n_estimators=400,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        eval_metric=\"auc\",\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    xgb.fit(X_train[num_cols], y_train)\n",
        "    val_probs_xgb = xgb.predict_proba(X_val[num_cols])[:, 1]\n",
        "    print(\"XGBoost ROC-AUC:\", roc_auc_score(y_val, val_probs_xgb))\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"XGBoost not available:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LightGBM (if installed)\n",
        "try:\n",
        "    from lightgbm import LGBMClassifier\n",
        "\n",
        "    lgbm = LGBMClassifier(\n",
        "        n_estimators=400,\n",
        "        max_depth=-1,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    lgbm.fit(X_train[num_cols], y_train)\n",
        "    val_probs_lgbm = lgbm.predict_proba(X_val[num_cols])[:, 1]\n",
        "    print(\"LightGBM ROC-AUC:\", roc_auc_score(y_val, val_probs_lgbm))\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"LightGBM not available:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic coefficients\n",
        "coef = pd.Series(log_reg.named_steps[\"clf\"].coef_[0], index=num_cols)\n",
        "coef.sort_values().plot(kind=\"barh\", figsize=(6, 4))\n",
        "plt.title(\"Logistic Regression Coefficients\")\n",
        "plt.show()\n",
        "\n",
        "# Random forest feature importance\n",
        "rf_importance = pd.Series(rf.feature_importances_, index=num_cols).sort_values(ascending=True)\n",
        "rf_importance.plot(kind=\"barh\", figsize=(6, 4))\n",
        "plt.title(\"Random Forest Feature Importance\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Threshold Selection (Top-N Targeting)\n",
        "\n",
        "Select a percentile threshold for outreach based on predicted risk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: target top 10% risk using best model (choose RF by default)\n",
        "probs = val_probs_rf\n",
        "\n",
        "threshold = np.quantile(probs, 0.90)\n",
        "val_df = val_df.copy()\n",
        "val_df[\"churn_risk\"] = probs\n",
        "val_df[\"target_flag\"] = (val_df[\"churn_risk\"] >= threshold).astype(int)\n",
        "\n",
        "val_df[[\"customer_id\", \"churned\", \"churn_risk\", \"target_flag\"]].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "956d12b1",
      "metadata": {},
      "source": [
        "## Save Churn Risk for Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0facf94e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# One row per customer: churn_risk for retention dashboard and targeting\n",
        "churn_df[\"churn_risk\"] = rf.predict_proba(\n",
        "    churn_df.drop(columns=[\"customer_id\", \"churned\", \"last_purchase\"])[num_cols]\n",
        ")[:, 1]\n",
        "churn_df[[\"customer_id\", \"churn_risk\"]].to_csv(\n",
        "    DATA_DIR / \"customer_churn_risk.csv\", index=False\n",
        ")\n",
        "print(\"Saved customer_churn_risk.csv for dashboard\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Model Artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save calibrated RF if available\n",
        "try:\n",
        "    joblib.dump(cal_rf, MODELS_DIR / \"churn_rf_calibrated.pkl\")\n",
        "except Exception:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a463c87",
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(log_reg, MODELS_DIR / \"churn_logreg.pkl\")\n",
        "joblib.dump(rf, MODELS_DIR / \"churn_rf.pkl\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (retail_ml)",
      "language": "python",
      "name": "retail_ml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
